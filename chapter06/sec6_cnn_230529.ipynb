{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "編集部注：2023年5月29日最終更新．コードの一部がお手元の書籍と異なる可能性がございます．正誤・更新情報は弊社ウェブサイトの[本書詳細ページ](https://www.yodosha.co.jp/jikkenigaku/book/9784758122634/index.html)をご参照ください．"
      ],
      "metadata": {
        "id": "371EdFbRVtoY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6r9ATFJImOU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/sec6/\n",
        "%ls -a "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXYwBSl5ZIoG"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-gradcam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiJqezNTcuR8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import scipy\n",
        "import random\n",
        "from tqdm import tqdm \n",
        "import glob\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as transforms\n",
        "\n",
        "from gradcam.utils import visualize_cam\n",
        "from gradcam import GradCAM, GradCAMpp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reVMpcBzc1Rq"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/sec6\" #フォルダパス\n",
        "im_fd = \"/cell_images/\" #上のパスからImageのあるフォルダの参照"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSP5x0KFalul"
      },
      "outputs": [],
      "source": [
        "folder = ['Uninfected','Parasitized']\n",
        "file0 = glob.glob(path + im_fd + folder[0] +\"/*.png\")[0]\n",
        "print(file0)\n",
        "image = Image.open(file0) # 画像ファイルの読み込み\n",
        "plt.imshow(image) #表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8zK0zfWb5n9"
      },
      "outputs": [],
      "source": [
        "np.array(image) #画像データを配列として表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPVQbjGammkn"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Get cpu or gpu device for training.\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyZYak58cyyt"
      },
      "outputs": [],
      "source": [
        "image_size = 128; #Imageサイズの指定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7IUjJAiiqz8"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "\n",
        "def seed_fix(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms = True\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "seed_fix(SEED)\n",
        "generator = torch.Generator()\n",
        "generator.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74olKl2cdoF6"
      },
      "outputs": [],
      "source": [
        "folder = ['Uninfected','Parasitized']\n",
        "X = [];\n",
        "y = [];\n",
        "usenumber = 1000\n",
        "for i,folname in enumerate(folder):\n",
        "    files1 = glob.glob(path + im_fd + folname +\"/*.png\"); #フォルダ内のファイル名を取得\n",
        "    f_number = len(files1) #randomに一部のデータのみ抽出するためのコード\n",
        "    files1, files2=torch.utils.data.random_split(files1,[usenumber,f_number - usenumber])\n",
        "    for j, file in enumerate(tqdm(files1)):\n",
        "        outcome = i\n",
        "        image = Image.open(file) # 画像ファイルの読み込み\n",
        "        image = image.convert(\"RGB\") # RGBモードに変換\n",
        "        image = image.resize((image_size, image_size)) # リサイズ\n",
        "        data = np.asarray(image) # 画像を配列に変換\n",
        "        X.append(data); # 複数枚を１つの配列に保存\n",
        "        y.append(outcome)  #正解ラベルをyとして保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su2AkQLWb3CR"
      },
      "outputs": [],
      "source": [
        "#配列データへの変換 ４次元のデータとして(画像枚数，RGBの層，画像の高さ，画像の横幅)になるように次元を入れ替え\n",
        "X = np.array(X).astype(np.float32).transpose(0,3,1,2)/255\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEzkL39kWP09"
      },
      "outputs": [],
      "source": [
        "Nall = X.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt8gbCpIgvWS"
      },
      "outputs": [],
      "source": [
        "tensor_X = torch.tensor(X, dtype=torch.float32) #Tensor型として変換\n",
        "tensor_y = torch.tensor(y, dtype=torch.int64) #Tensor型として変換"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23ZN8ziRDP9E"
      },
      "outputs": [],
      "source": [
        "dataset = torch.utils.data.TensorDataset(tensor_X,tensor_y)# 目的変数と入力変数をまとめてdatasetに変換\n",
        "n_train = int(Nall * 0.7) # Training データ数\n",
        "n_val = int(Nall * 0.2)   # Validation データ数\n",
        "n_test = Nall - n_train - n_val # Test データ数\n",
        "train_x, val_x, test_x = torch.utils.data.random_split(dataset, [n_train, n_val,n_test]) # データセットの分割\n",
        "print(\"train =\",n_train,\",validation =\",n_val,\",Test =\",n_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yarYALOoiUw9"
      },
      "outputs": [],
      "source": [
        "batch_size = 64 #バッチサイズの指定\n",
        "train_dataloader = DataLoader(train_x, batch_size=batch_size, shuffle=True)  # data loaderとして指定\n",
        "val_dataloader   = DataLoader(val_x,   batch_size=batch_size, shuffle=False)\n",
        "test_dataloader  = DataLoader(test_x,  batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGUUV3AvX-Lt"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_shape=(3,128,128),output_size=2):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=input_shape[0], out_channels=16, kernel_size=3, padding='same'),nn.ReLU(),nn.MaxPool2d(2,2))\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding='same'),nn.ReLU(),nn.MaxPool2d(2,2))\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding='same'),nn.ReLU(),nn.MaxPool2d(2,2))\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same'),nn.ReLU(),nn.MaxPool2d(2,2))\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.CNN_outshape = self._get_conv_output(input_shape)\n",
        "        self.linear = nn.Linear(self.CNN_outshape, output_size)\n",
        "    def _get_conv_output(self, shape):\n",
        "        bs = 1\n",
        "        dummy_x = torch.empty(bs, *shape)\n",
        "        x = self._forward_features(dummy_x)\n",
        "        CNN_outshape = x.flatten(1).size(1)\n",
        "        return CNN_outshape\n",
        "    def _forward_features(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.flatten(x)\n",
        "        return x     \n",
        "    def forward(self, x):\n",
        "        x = self._forward_features(x)\n",
        "        x = self.linear(x.flatten(1))\n",
        "        return x\n",
        "model = CNN().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2wfRyNwlz39"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop((image_size,image_size)),\n",
        "    transforms.RandomHorizontalFlip(p=0.4),\n",
        "    transforms.RandomVerticalFlip(p=0.4),\n",
        "    transforms.RandomRotation(degrees=[-7.5, 7.5])\n",
        "    ]\n",
        ") #Data augumentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_1W1LWIB2Nv"
      },
      "outputs": [],
      "source": [
        "#最適化\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay= 0.005)\n",
        "\n",
        "def train(train_loader): #Training\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = len(train_loader.dataset)\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        #data augumentation\n",
        "        #images = transform(images)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        predicted = outputs.max(1, keepdim=True)[1]\n",
        "        labels = labels.view_as(predicted)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "    train_loss = running_loss / len(train_loader) \n",
        "    train_acc = correct / total\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def valid(test_loader): #Validation\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = len(test_loader.dataset)\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            predicted = outputs.max(1, keepdim=True)[1]\n",
        "            labels = labels.view_as(predicted)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "    val_loss = running_loss / len(test_loader)\n",
        "    val_acc = correct / total\n",
        "    return val_loss, val_acc\n",
        "\n",
        "#空の配列\n",
        "acc_list = []\n",
        "loss_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7--9MRHX-Lt"
      },
      "outputs": [],
      "source": [
        "nepoch = 300\n",
        "\n",
        "#Fitting\n",
        "for epoch in range(nepoch):\n",
        "    loss, acc = train(train_dataloader)\n",
        "    val_loss, val_acc = valid(val_dataloader)\n",
        "    print('epoch %d, loss: %.4f acc: %.4f val_loss: %.4f val_acc: %.4f' % (epoch, loss,acc, val_loss, val_acc))\n",
        "    loss_list.append(loss)\n",
        "    acc_list.append(acc)\n",
        "    val_loss_list.append(val_loss)\n",
        "    val_acc_list.append(val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XI4WwTyXX-Lu"
      },
      "outputs": [],
      "source": [
        "#modelの保存\n",
        "torch.save(model, 'model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piHvs21kK8Ax"
      },
      "outputs": [],
      "source": [
        "#読み込み\n",
        "model = torch.load('model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8sM7oJUATzd"
      },
      "outputs": [],
      "source": [
        "print('正解率：',val_acc_list[-1]*100, '%')\n",
        "\n",
        "#学習過程の表示\n",
        "plt.plot(range(nepoch), loss_list, 'r-', label='train_loss')\n",
        "plt.plot(range(nepoch), val_loss_list, 'b-', label='val_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(nepoch), acc_list, 'b-', label='acc')\n",
        "plt.plot(range(nepoch), val_acc_list, 'g-', label='val_acc')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLxIscDdH1Xb"
      },
      "source": [
        "モデル評価：テストデータへの当てはめ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlqsNLwmDb-R"
      },
      "outputs": [],
      "source": [
        "#For Test\n",
        "def test(test_loader):\n",
        "    prob = []\n",
        "    pred = []\n",
        "    true = []\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = len(test_loader.dataset)\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            lprob, predicted = outputs.max(1, keepdim=True)\n",
        "            labels = labels.view_as(predicted)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            prob = np.append(prob, scipy.special.expit(torch.Tensor.numpy(outputs[:,1].to('cpu'))))\n",
        "            pred = np.append(pred, torch.Tensor.numpy(predicted.to('cpu')))\n",
        "            true = np.append(true, torch.Tensor.numpy(labels.to('cpu')))\n",
        "    return prob, pred, true\n",
        "\n",
        "prob, pred, true,  = test(test_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAuiwaHzIEu8"
      },
      "outputs": [],
      "source": [
        "# testデータの画像と予測ラベル・正答ラベル・予測確率を出力\n",
        "plt.figure(figsize = (25, 25))\n",
        "for i in range(20):\n",
        "    plt.subplot(5, 4, i + 1)\n",
        "    plt.axis(\"off\")\n",
        "    if pred[i] == true[i]:\n",
        "        plt.title(\"pred:\"+str(pred[i].astype(np.uint8))+' - '+\"true:\"+str(true[i].astype(np.uint8))+'\\n'+'Prob.(Y=1) = %.4f' % (prob[i]))\n",
        "    else:\n",
        "        plt.title(\"pred:\"+str(pred[i].astype(np.uint8))+' - '+\"true:\"+str(true[i].astype(np.uint8))+'\\n'+'Prob.(Y=1) = %.4f' % (prob[i]), color = \"red\") # 分類が間違っていた場合，赤字で書き込む\n",
        "        \n",
        "    tmp = test_x[i][0].to('cpu').detach().numpy().copy() \n",
        "    tmp = tmp.transpose(1, 2, 0)\n",
        "    img_pil = Image.fromarray((tmp*255).astype(np.uint8))\n",
        "    plt.imshow(img_pil)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXpTUm7JIGRn"
      },
      "outputs": [],
      "source": [
        "#2×2行列に正解不正解まとめる\n",
        "cmat = confusion_matrix(true, pred)\n",
        "print(cmat)\n",
        "\n",
        "#感度特異度の算出\n",
        "tn, fp, fn, tp = cmat.flatten()\n",
        "\n",
        "acc = round((tp+tn)/(tp+tn+fp+fn),4)\n",
        "sen = round(tp/(tp+fn),4)\n",
        "spe = round(tn/(tn+fp),4)\n",
        "ppv = round(tp/(tp+fp),4)\n",
        "npv = round(tn/(tn+fn),4)\n",
        "print(\"acc=\",acc,\"sen=\",sen,\" ,spe=\",spe,\" ,ppv=\",ppv,\" ,npv=\",npv)\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ph07uJCqIU_j"
      },
      "outputs": [],
      "source": [
        "#ROC curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(true, prob)     \n",
        "plt.plot(fpr, tpr, marker='o')\n",
        "plt.xlabel('1-Specificity')\n",
        "plt.ylabel('Sensitivity')\n",
        "plt.grid()\n",
        "#plt.savefig(path+'/roc_curve.png')\n",
        "\n",
        "Youden_index = tpr-fpr    \n",
        "index = np.where(Youden_index==max(Youden_index))[0][0]\n",
        "\n",
        "cutoff = thresholds[index]\n",
        "sensitivity = tpr[index]\n",
        "specificity = 1 - fpr[index]\n",
        "print(\"Cutoff-value:\",round(cutoff,4),\"Sensitivity:\",round(sensitivity,4),\"Specificity: \",round(specificity,4))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5uVsyLzz9Mw"
      },
      "outputs": [],
      "source": [
        "#!pip install grad-cam -q\n",
        "#!conda install grad-cam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVTPmcwvHtZF"
      },
      "source": [
        "Grad-CAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OFkVXOoRlTY"
      },
      "outputs": [],
      "source": [
        "# Grad-CAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBWnJQlCRtpy"
      },
      "outputs": [],
      "source": [
        "#読み込み\n",
        "model = torch.load('model.pt')\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLjz8Jx7SS6-"
      },
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcpnBtHqUZfn"
      },
      "outputs": [],
      "source": [
        "target_layer = model.conv4[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2LGP4gISQLx"
      },
      "outputs": [],
      "source": [
        "gradcam = GradCAM(model, target_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7CeJ5BPXY4b"
      },
      "outputs": [],
      "source": [
        "image_number = 1\n",
        "torch_img = torch.tensor(np.expand_dims(test_x[image_number][0], 0)).to(device) #画像をTorch\n",
        "images = []\n",
        "mask, _ = gradcam(torch_img)\n",
        "heatmap, result = visualize_cam(mask, torch_img)\n",
        "image0 = torch.squeeze(torch_img,dim=0)\n",
        "images.extend([image0.cpu(), result])\n",
        "grid_image = torchvision.utils.make_grid(images, nrow=2)\n",
        "transforms.ToPILImage()(grid_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhWr0VMqHlHV"
      },
      "source": [
        "Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVH9cwOxTLzq"
      },
      "outputs": [],
      "source": [
        "model = models.vgg16(pretrained=True)# 事前トレーニングされたVGG16モデルを取得\n",
        "model.classifier[6] = nn.Linear(in_features=4096,out_features=2)   # 入力サイズはデフォルトの4096 出力はデフォルトの1000から2に変更\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #GPUで使用できるように指定\n",
        "model = model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTBJMuAGTLzq"
      },
      "outputs": [],
      "source": [
        "# 転移学習で学習させるパラメータ\n",
        "params_to_update = []\n",
        "update_param_names = ['classifier.6.weight', 'classifier.6.bias']\n",
        "for name, param in model.named_parameters():\n",
        "    if name in update_param_names:\n",
        "        param.requires_grad = True \n",
        "        params_to_update.append(param) \n",
        "        print(name) \n",
        "    else:\n",
        "        param.requires_grad = False # 出力層以外は勾配計算なし"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrgODMKvTLzq"
      },
      "outputs": [],
      "source": [
        "# 損失関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# オプティマイザー\n",
        "optimizer = torch.optim.SGD(params=params_to_update, lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "\n",
        "#Trainig用\n",
        "def train(train_loader):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = len(train_loader.dataset)\n",
        "    \n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        predicted = outputs.max(1, keepdim=True)[1]\n",
        "        labels = labels.view_as(predicted)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "\n",
        "    train_loss = running_loss / len(train_loader) \n",
        "    train_acc = correct / total\n",
        "    return train_loss, train_acc\n",
        "\n",
        "\n",
        "\n",
        "#Validation用\n",
        "def valid( test_loader):\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = len(test_loader.dataset)\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            predicted = outputs.max(1, keepdim=True)[1]\n",
        "            labels = labels.view_as(predicted)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            #break\n",
        "            \n",
        "    val_loss = running_loss / len(test_loader)\n",
        "    val_acc = correct / total\n",
        "    return val_loss, val_acc\n",
        "\n",
        "'''誤差(loss)を記録する空の配列を用意'''\n",
        "acc_list = []\n",
        "loss_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BeG5Er0TLzq"
      },
      "outputs": [],
      "source": [
        "nepoch = 50\n",
        "\n",
        "#学習 1回目の学習は行わず評価のみ\n",
        "for epoch in range(nepoch):\n",
        "    \n",
        "    if(epoch > 0):\n",
        "        loss, acc = train(train_dataloader)\n",
        "    else:\n",
        "        loss, acc = valid(train_dataloader)\n",
        "\n",
        "    val_loss, val_acc = valid(val_dataloader)\n",
        "    print('epoch %d, loss: %.4f acc: %.4f val_loss: %.4f val_acc: %.4f' % (epoch, loss,acc, val_loss, val_acc))\n",
        "    loss_list.append(loss)\n",
        "    acc_list.append(acc)\n",
        "    val_loss_list.append(val_loss)\n",
        "    val_acc_list.append(val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEpTJcX5TLzq"
      },
      "outputs": [],
      "source": [
        "#modelの保存\n",
        "torch.save(model, 'model_finetuning.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqZe4UjVTLzr"
      },
      "outputs": [],
      "source": [
        "print('正解率：',val_acc_list[-1]*100, '%')\n",
        "\n",
        "'''結果の表示'''\n",
        "plt.plot(range(nepoch), loss_list, 'r-', label='train_loss')\n",
        "plt.plot(range(nepoch), val_loss_list, 'b-', label='val_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(nepoch), acc_list, 'b-', label='acc')\n",
        "plt.plot(range(nepoch), val_acc_list, 'g-', label='val_acc')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}