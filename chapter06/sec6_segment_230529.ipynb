{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "編集部注：2023年5月29日最終更新．コードの一部がお手元の書籍と異なる可能性がございます．正誤・更新情報は弊社ウェブサイトの[本書詳細ページ](https://www.yodosha.co.jp/jikkenigaku/book/9784758122634/index.html)をご参照ください．"
      ],
      "metadata": {
        "id": "3qgAOGlXV8K5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5nyqAmFKKQW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/sec6/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybze2BnyKTU0"
      },
      "outputs": [],
      "source": [
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from time import time\n",
        "from copy import deepcopy\n",
        "from tqdm import tqdm \n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_H9fkkba4_y"
      },
      "outputs": [],
      "source": [
        "folder = ['benign', 'malignant', 'normal']\n",
        "def load_data():\n",
        "  images = []\n",
        "  masks = []\n",
        "  for i,folname in enumerate(tqdm(folder)):\n",
        "      files1 = glob.glob(path + \"Dataset_BUSI_with_GT/\" + folname +\"/*_mask.png\");\n",
        "      for j, file in enumerate(tqdm(files1)):\n",
        "          filename =   file.rsplit(\"/\",1)[1].rsplit(\"_\",1)[0]\n",
        "          image = resize(imread(path + \"Dataset_BUSI_with_GT/\" + folname +\"/\"+filename + \".png\",as_gray=True), output_shape=(128, 128))\n",
        "          mask = resize(imread(path + \"Dataset_BUSI_with_GT/\" + folname +\"/\"+filename + \"_mask.png\",as_gray=True), output_shape=(128, 128))\n",
        "          images.append(image)\n",
        "          masks.append(mask)\n",
        "  return np.array(images), np.array(masks)\n",
        "images, masks = load_data()\n",
        "print(f\"Images shape: {images.shape}\",\n",
        "      f\"Masks shape: {masks.shape}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8tMxCpjJuv2"
      },
      "outputs": [],
      "source": [
        "def flip(images, labels, axis):\n",
        "    aug_images = np.flip(images, axis) #画像の変換\n",
        "    aug_labels = np.flip(labels, axis) #ラベルの変換\n",
        "    return aug_images, aug_labels\n",
        "def augment(images, labels):\n",
        "    aug_y_images, aug_y_labels = flip(images, labels, axis=2) #縦\n",
        "    images = np.concatenate([images, aug_y_images])\n",
        "    labels = np.concatenate([labels, aug_y_labels])\n",
        "    aug_x_images, aug_x_labels = flip(images, labels, axis=1) #横\n",
        "    images = np.concatenate([images, aug_x_images])\n",
        "    labels = np.concatenate([labels, aug_x_labels])\n",
        "    return images, labels\n",
        "images, masks = augment(images, masks)\n",
        "print(f\"Images shape: {images.shape}\",f\"Masks shape: {masks.shape}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjivBoLXJuv3"
      },
      "outputs": [],
      "source": [
        "#Figure output\n",
        "f, axis = plt.subplots(nrows=4, ncols=2, constrained_layout=True, figsize=(10, 10))\n",
        "for i in range(4):\n",
        "    axis[i, 0].imshow(images[i], cmap=\"gray\")\n",
        "    axis[i, 1].imshow(masks[i], cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ_LqiDeJuv3"
      },
      "outputs": [],
      "source": [
        "images = np.expand_dims(images, axis=3)\n",
        "masks = np.expand_dims(masks, axis=3)\n",
        "x_train, x_val, y_train, y_val = train_test_split(images, masks, test_size= 0.1, shuffle=True, random_state=1111)\n",
        "x_test, x_val, y_test, y_val = train_test_split(x_val, y_val, test_size=0.5, shuffle=True, random_state=11)\n",
        "\n",
        "print(f\"Train arrays shape: {x_train.shape}, {y_train.shape}\")\n",
        "print(f\"Test arrays shape: {x_test.shape}, {y_test.shape}\")\n",
        "print(f\"Validation arrays shape: {x_val.shape}, {y_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKbGkDL4Juv4"
      },
      "outputs": [],
      "source": [
        "#GPUへ　Tentor\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "images_format = torch.float32\n",
        "masks_format = torch.float32\n",
        "\n",
        "# Free memory\n",
        "del images, masks\n",
        "\n",
        "# Convert Numpy to tensors\n",
        "train_inputs = torch.from_numpy(x_train).to(images_format).to(device)\n",
        "train_outputs = torch.from_numpy(y_train).to(masks_format).to(device)\n",
        "val_inputs = torch.from_numpy(x_val).to(images_format).to(device)\n",
        "val_outputs = torch.from_numpy(y_val).to(masks_format).to(device)\n",
        "test_inputs = torch.from_numpy(x_test).to(images_format).to(device)\n",
        "test_outputs = torch.from_numpy(y_test).to(masks_format).to(device)\n",
        "train_inputs = train_inputs.permute(0, 3, 1, 2)\n",
        "val_inputs = val_inputs.permute(0, 3, 1, 2)\n",
        "test_inputs = test_inputs.permute(0, 3, 1, 2)\n",
        "train_outputs = train_outputs.permute(0, 3, 1, 2)\n",
        "val_outputs = val_outputs.permute(0, 3, 1, 2)\n",
        "test_outputs = test_outputs.permute(0, 3, 1, 2)\n",
        "\n",
        "print(f\"Train tensor shape: {train_inputs.shape}, {train_outputs.shape}\")\n",
        "print(f\"Test tensor shape: {test_inputs.shape}, {test_outputs.shape}\")\n",
        "print(f\"Validation tensor shape: {val_inputs.shape}, {val_outputs.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuE7QMUeJuv4"
      },
      "outputs": [],
      "source": [
        "#model specificaition\n",
        "class conv2(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(conv2, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(up, self).__init__()\n",
        "        self.up_scale = nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2)\n",
        "    def forward(self, x1, x2):\n",
        "        x2 = self.up_scale(x2)\n",
        "        diffY = x1.size()[2] - x2.size()[2]\n",
        "        diffX = x1.size()[3] - x2.size()[3]\n",
        "        x2 = F.pad(x2, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return x\n",
        "class down_layer(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down_layer, self).__init__()\n",
        "        self.pool = nn.AvgPool2d(2, stride=2, padding=0)\n",
        "        self.conv = conv2(in_ch, out_ch)\n",
        "    def forward(self, x):\n",
        "        x = self.conv(self.pool(x))\n",
        "        return x\n",
        "class up_layer(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(up_layer, self).__init__()\n",
        "        self.up = up(in_ch, out_ch)\n",
        "        self.conv = conv2(in_ch, out_ch)\n",
        "    def forward(self, x1, x2):\n",
        "        a = self.up(x1, x2)\n",
        "        x = self.conv(a)\n",
        "        return x\n",
        "    \n",
        "class unet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(unet, self).__init__()\n",
        "        self.conv1 = conv2(1, 8)\n",
        "        self.down1 = down_layer(8, 16)\n",
        "        self.down2 = down_layer(16, 32)\n",
        "        self.down3 = down_layer(32, 64)\n",
        "        self.down4 = down_layer(64, 128)\n",
        "        self.down5 = down_layer(128, 256)\n",
        "        self.down6 = down_layer(256, 512)\n",
        "        self.down7 = down_layer(512, 1024)\n",
        "        self.up1 = up_layer(1024, 512)\n",
        "        self.up2 = up_layer(512, 256)\n",
        "        self.up3 = up_layer(256, 128)\n",
        "        self.up4 = up_layer(128, 64)\n",
        "        self.up5 = up_layer(64, 32)\n",
        "        self.up6 = up_layer(32, 16)\n",
        "        self.up7 = up_layer(16, 8)\n",
        "        self.last_conv = nn.Conv2d(8, 1, 1)\n",
        "        self.dilute = nn.Conv2d(1, 1, 1)\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x6 = self.down5(x5)\n",
        "        x7 = self.down6(x6)\n",
        "        x8 = self.down7(x7)\n",
        "        x1_up = self.up1(x7, x8)\n",
        "        x2_up = self.up2(x6, x1_up)\n",
        "        x3_up = self.up3(x5, x2_up)\n",
        "        x4_up = self.up4(x4, x3_up)\n",
        "        x5_up = self.up5(x3, x4_up)\n",
        "        x6_up = self.up6(x2, x5_up)\n",
        "        x7_up = self.up7(x1, x6_up)\n",
        "    \n",
        "        output = self.last_conv(x7_up)\n",
        "        output = self.dilute(output)\n",
        "        output = torch.sigmoid(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6OoyS3yJuv5"
      },
      "outputs": [],
      "source": [
        "#Loss function\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "    def forward(self, inputs, targets, smooth=1):    \n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (inputs * targets).sum()                            \n",
        "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
        "        return 1 - dice\n",
        "unet = unet().to(device)\n",
        "optimizer = torch.optim.Adam(unet.parameters(), lr=0.001)\n",
        "criterion = DiceLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0OT6jl_Juv5"
      },
      "outputs": [],
      "source": [
        "#Model Training\n",
        "best_loss = np.inf\n",
        "epochs = 200\n",
        "patience = 5\n",
        "batch_size = 20\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "n_epochs = []\n",
        "\n",
        "total_train = train_inputs.size()[0]\n",
        "total_val = val_inputs.size()[0]\n",
        "\n",
        "t0 = time()\n",
        "for epoch in range(epochs):\n",
        "    unet.train()\n",
        "    running_loss = 0\n",
        "    running_valloss = 0\n",
        "    n_epochs.append(epoch)\n",
        "    train_perm = torch.randperm(total_train)\n",
        "    val_perm = torch.randperm(total_val)\n",
        "\n",
        "    for i in range(0, total_train, batch_size):\n",
        "        optimizer.zero_grad()\n",
        "        indices = train_perm[i:i+batch_size]\n",
        "        batch_x, batch_y = train_inputs[indices], train_outputs[indices]\n",
        "        outputs = unet(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss\n",
        "\n",
        "    running_loss = running_loss.cpu().detach() / total_train\n",
        "    train_losses.append(running_loss)\n",
        "\n",
        "    for j in range(0, total_val, batch_size):\n",
        "        unet.eval()\n",
        "        indices = val_perm[j:j+batch_size]\n",
        "        batch_x, batch_y = val_inputs[indices], val_outputs[indices]\n",
        "        outputs = unet(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        running_valloss += loss\n",
        "\n",
        "    running_valloss = running_valloss.cpu().detach() / total_val\n",
        "    val_losses.append(running_valloss)\n",
        "\n",
        "\n",
        "    if running_valloss < best_loss:\n",
        "        best_loss = running_valloss\n",
        "        cost_patience = patience\n",
        "        state_dict = deepcopy(unet.state_dict())\n",
        "        print(f\"\\tEpoch: {epoch+1}/{epochs}, \", f\"Train Loss: {running_loss:.3g}, \", f\"Val Loss: {running_valloss:.3g}\")\n",
        "\n",
        "    else:\n",
        "        cost_patience -= 1\n",
        "        if cost_patience < 0:\n",
        "            print(f\"\\nEarly stopping after {patience} epochs of no improvements\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(f\"\\tEpoch: {epoch+1}/{epochs}, \",f\"Train Loss: {running_loss:.3g}, \", f\"Val Loss: {running_valloss:.3g} - No improvement\", f\"-> Remaining patience: {cost_patience}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILbuyNtaJuv5"
      },
      "outputs": [],
      "source": [
        "plt.plot(n_epochs, train_losses, label='train_loss')\n",
        "plt.plot(n_epochs, val_losses, label='val_loss')\n",
        "plt.legend(loc='upper center')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "no_improvement_line = n_epochs[-1] - patience\n",
        "plt.axvline(x=no_improvement_line, color='r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tG0isPNFJuv5"
      },
      "outputs": [],
      "source": [
        "torch.save(state_dict, \"model_unet.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0bRZFPqJuv6"
      },
      "outputs": [],
      "source": [
        "#Prediction\n",
        "\n",
        "predictions = unet(test_inputs).cpu().detach().numpy()\n",
        "images = test_inputs.cpu().detach().numpy()\n",
        "masks = test_outputs.cpu().detach().numpy()\n",
        "\n",
        "f, axis = plt.subplots(nrows=4, ncols=3, constrained_layout=True, figsize=(10, 10))\n",
        "for i in range(4):\n",
        "    axis[i, 0].imshow(images[i][0], cmap=\"gray\")\n",
        "    axis[i, 0].set_title(\"image\")\n",
        "    axis[i, 1].imshow(masks[i][0], cmap=\"gray\")\n",
        "    axis[i, 1].set_title(\"target\")\n",
        "    axis[i, 2].imshow(predictions[i][0], cmap=\"gray\")\n",
        "    axis[i, 2].set_title(\"predict\")\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}