{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQVEfOXEy9db"
      },
      "source": [
        "# 第7章　実践編2：腫瘍特異的ネオ抗原の機械学習を用いた予測腫瘍特異的ネオ抗原の機械学習を用いた予測\n",
        "\n",
        "-長谷川嵩矩"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "編集部注：2023年5月29日最終更新．コードの一部がお手元の書籍と異なる可能性がございます．正誤・更新情報は弊社ウェブサイトの[本書詳細ページ](https://www.yodosha.co.jp/jikkenigaku/book/9784758122634/index.html)をご参照ください．"
      ],
      "metadata": {
        "id": "A3XuIg2BWM6G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZpvMLSIzam0"
      },
      "source": [
        "##### 入力7-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHk6ObDqzhJ5"
      },
      "outputs": [],
      "source": [
        "! pip install torchmetrics==0.7.1\n",
        "! pip install biopython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUnBsDhLze4C"
      },
      "source": [
        "##### 入力7-2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2uqo2JuzkIt"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional\n",
        "import torch.optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torchmetrics.functional import precision_recall\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import Bio\n",
        "from Bio.Seq import Seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vttqWrazfAf"
      },
      "source": [
        "##### 入力7-3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJ-7zceuzp-0"
      },
      "outputs": [],
      "source": [
        "# Chr     Start       End Ref Alt Func.refGene Gene.refGene   GeneDetail.refGene ExonicFunc.refGene                              AAChange.refGene   cytoBand depth_tumor variantNum_tumor depth_normal\n",
        "# 1 116941338 116941338   T   C       exonic       ATP1A1           synonymous                SNV   ATP1A1:NM_001160234:exon16:c.T2127C:p.D709D     1p13.1         100               39          111\n",
        "# 4  24556416  24556416   T   C       exonic        DHX15        nonsynonymous                SNV        DHX15:NM_001358:exon5:c.A1012G:p.T338A     4p15.2         143               47          151\n",
        "# 4  70156404  70156404   -   T       exonic      UGT2B28           frameshift          insertion   UGT2B28:NM_053039:exon5:c.1186dupT:p.L395fs     4q13.2          43               15           41\n",
        "# 6  75899298  75899298   T   -       exonic      COL12A1           frameshift           deletion    COL12A1:NM_004370:exon6:c.628delA:p.I210fs       6q13         122               38           73\n",
        "# 9  89561162  89561162   C   T       exonic         GAS1        nonsynonymous                SNV          GAS1:NM_002048:exon1:c.G533A:p.R178H    9q21.33          20                5           26\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOYu8ixIzfDX"
      },
      "source": [
        "##### 入力7-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhwUGdG1z9yU"
      },
      "outputs": [],
      "source": [
        "normal_rna = Seq(\"GCATGCTGCATGCATGATGCCATGCATGCTGCATGCTGCATG\")\n",
        "tumor_rna = Seq(\"GCATGCTGCATGCATGATGCCACGCATGCTGCATGCTGCATG\")\n",
        "print(\" 野生型RNA配列:..\" + str(normal_rna) + \"..\")\n",
        "print(\"腫瘍特異的RNA配列:..\" + str(tumor_rna) + \"..\")\n",
        "\n",
        "print(\" 野生型タンパク質配列:..\" + str(normal_rna.translate()) + \"..\")\n",
        "print(\"腫瘍特異的タンパク質配列:..\" + str(tumor_rna.translate()) + \"..\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noq9-U1qzfGr"
      },
      "source": [
        "##### 入力7-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mgkgt5sh0DAV"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "1. まずはデータをダウンロードする\n",
        "'''\n",
        "data_dir = './pepdata/' # データセットの格納先\n",
        "if not os.path.exists(data_dir): # 指定したフォルダーが存在しない場合は作成する\n",
        "    os.mkdir(data_dir)\n",
        "\n",
        "# Hao et al. 2021の論文で使われている公開データセットのダウンロード先\n",
        "# 今回はHLA Class1 A0301のデータを利用\n",
        "train_url = 'https://github.com/haoqing12/APPM/raw/master/DATA/train_data/A0301'\n",
        "test_url = 'https://github.com/haoqing12/APPM/raw/master/DATA/test_data/A0301'\n",
        "\n",
        "# ファイル名を連結して格納先を指定\n",
        "train_save_path = os.path.join(data_dir, 'train_A0301.csv')\n",
        "test_save_path = os.path.join(data_dir, 'test_A0301.csv')\n",
        "\n",
        "# ダウンロードを実行\n",
        "urllib.request.urlretrieve(train_url, train_save_path)\n",
        "urllib.request.urlretrieve(test_url, test_save_path)\n",
        "\n",
        "print(\"Stored training-data name is \", train_save_path)\n",
        "print(\"Stored test-data name is \", test_save_path)\n",
        "pd.read_csv(train_save_path, nrows=5).head # データセットの中身を確認\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0quMSzvzfJG"
      },
      "source": [
        "##### 入力7-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr5_gP6O0OmO"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "2. トランスフォーマーオブジェクトの作成\n",
        "'''\n",
        "class PepTransform():\n",
        "    allSequences = 'ACEDGFIHKMLNQPSRTWVYZ' # アミノ酸配列\n",
        "    char2int = dict((c, i) for i, c in enumerate(allSequences)) # アミノ酸配列にインデックスを付けてdict型に格納\n",
        "  \n",
        "    def peptideOneHotMap(self, peptide):\n",
        "        peptide_integer = [self.char2int[char] for char in peptide] # 入力したペプチドのアミノ酸を上記で定義した番号に変換\n",
        "        peptide_onehot = list() # OneHotベクトル形式のペプチド配列\n",
        "        for value in peptide_integer:\n",
        "            letter = [0 for _ in range(len(self.allSequences))] # 要素が0でlen(self. allSequences)の長さを持つ配列を作成\n",
        "            letter[value] = 1 # 対応するアミノ酸の要素を1で埋める\n",
        "            peptide_onehot.append(letter) # 配列をリストに加える\n",
        "        return np.asarray(peptide_onehot)\n",
        "\n",
        "    def __init__(self):\n",
        "        '''インスタンス変数の初期化\n",
        "        '''\n",
        "\n",
        "    def __call__(self, peptide):\n",
        "        '''コールバック関数\n",
        "        与えられたpeptide配列に対応するOneHotベクトルのリストを返す\n",
        "        '''\n",
        "        return self.peptideOneHotMap(peptide)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oft9sqXTzfLl"
      },
      "source": [
        "##### 入力7-7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v04b-jS10pim"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "3. ペプチドの長さを一定に変更する関数を作成\n",
        "'''\n",
        "# ペプチド長を11に固定し，足りない部分にZを埋め込んだペプチドを返す関数を定義する\n",
        "# 入力はpandas.Seriesであり，listに変換して返す\n",
        "def complementPeptides(peptides_series):\n",
        "    peptides_list=peptides_series.tolist()\n",
        "    for i in range(len(peptides_list)):\n",
        "        if len(peptides_list[i]) < 11: # 11未満の場合は後ろにZを足す\n",
        "            peptides_list[i] = peptides_list[i] + 'Z'*(11 - len(peptides_list[i]))\n",
        "        else:\n",
        "            peptides_list[i] = peptides_list[i][:11] # 11以上の場合は11番目までを残す\n",
        "    return peptides_list\n",
        "\n",
        "\n",
        "#例\n",
        "peptides_list = ['ACCMHDACCMHDAAA', 'ACCMHDATH']\n",
        "for i in range(len(peptides_list)):\n",
        "    if len(peptides_list[i]) < 11:\n",
        "        peptides_list[i] = peptides_list[i] + 'Z' * (11 - len(peptides_list[i]))\n",
        "    else:\n",
        "        peptides_list[i] = peptides_list[i][:11]\n",
        "    print(\"Generated Peptide is: \" + peptides_list[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M08_JQLe3i7Z"
      },
      "source": [
        "##### 入力7-8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BltV204d3lxQ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "4. 学習に用いるペプチドのデータセットを作成するクラス\n",
        "'''\n",
        "class MakeDataset(data.Dataset):\n",
        "    '''\n",
        "    PyTorchのDatasetクラスを継承\n",
        "    Attributes:\n",
        "        save_path: ペプチドのリストを有するテキストファイルの格納先\n",
        "        transform: 前処理クラスのインスタンス\n",
        "    Returns:\n",
        "        X: OneHotベクトルに変換したtorch.Tensor型の学習用入力ファイル\n",
        "        Y: 正解ラベル(結合親和性の有無)\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, save_path, transform=None):\n",
        "        '''インスタンス変数の初期化\n",
        "        '''\n",
        "        super().__init__() # スーパークラスの__init__()を実行\n",
        "        \n",
        "        df = pd.read_csv(save_path, header=0) # データを読み込む\n",
        "        df = df[df['Peptide'].str.contains('X') == False] # 不明なペプチドが含まれているPeptide配列を削除\n",
        "        df = df[df['Peptide'].str.contains('B') == False] # 不明なペプチドが含まれているPeptide配列を削除\n",
        "        df = df[df['Peptide'].str.contains('U') == False] # 不明なペプチドが含まれているPeptide配列を削除\n",
        "        \n",
        "        print('{0}のファイル:'.format(save_path))\n",
        "        print('#Original Negative data is: ' + str(df.loc[df['BindingCategory'] == 0].shape))\n",
        "        print('#Original Positive data is: ' + str(df.loc[df['BindingCategory'] == 1].shape) + '\\n')\n",
        "        \n",
        "        # 学習時のみPositiveサンプルのオーバーサンプリングを行う\n",
        "        if \"train\" in save_path:\n",
        "            df_0 = df.loc[df['BindingCategory'] == 0]\n",
        "            df_1 = df.loc[df['BindingCategory'] == 1]\n",
        "            df = pd.concat([df_0, df_1, df_1], axis=0) # Positiveサンプルを2倍に増やす\n",
        "            print('オーバーサンプリング後:')\n",
        "            print('#Original Negative data is: ' + str(df.loc[df['BindingCategory'] ==0].shape))\n",
        "            print('#Original Positive data is: ' + str(df.loc[df['BindingCategory'] == 1].shape) + '\\n')\n",
        "        df = df.sample(frac=1).reset_index() # インデックスをリセットする\n",
        "        \n",
        "        self.peptides =complementPeptides(df['Peptide']) # OneHotベクトルのペプチド配列\n",
        "        self.y = df['BindingCategory'] # 正解ラベル\n",
        "        self.transform = transform # 前処理クラスのインスタンス\n",
        "    def __len__(self):\n",
        "        '''len(obj)で実行されたときにコールされる関数\n",
        "        ここではペプチド総数を返すようにセット\n",
        "        '''\n",
        "        return len(self.peptides)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''Datasetクラスの__getitem__()をオーバーライドする\n",
        "        OneHotベクトルをtorch.Tensor型に変換して返す\n",
        "        '''\n",
        "\n",
        "        # index番目のペプチドを取得\n",
        "        peptide_transformed = self.transform(self.peptides[index])\n",
        "\n",
        "        X = torch.from_numpy(peptide_transformed.astype(np.float32)).clone() # numpy.ndarrayからtorch.Tensorに変換\n",
        "        Y = torch.tensor(self.y[index], dtype=torch.long).clone() # 同様にtorch.Tensorに変換\n",
        "        return torch.reshape(X, (1, X.shape[0], X.shape[1])), Y # PyTorchの入力データは(バッチサイズ(外側から指定)，チャネル数(=1)，配列の次元)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk6V9phnzfN6"
      },
      "source": [
        "##### 入力7-9\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0wvZ_KN0_VH"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "5. データローダーの生成\n",
        "'''\n",
        "batch_size = 32    # ミニバッチのサイズを指定\n",
        "\n",
        "# MakeDatasetで訓練データと正解ラベルを取得\n",
        "train_dataset = MakeDataset(\n",
        "    save_path = train_save_path, \n",
        "    transform = PepTransform())\n",
        "\n",
        "# MakeDatasetで検証データと正解ラベルを取得\n",
        "test_dataset = MakeDataset(\n",
        "    save_path = test_save_path, \n",
        "    transform = PepTransform())\n",
        "\n",
        "# (32, 1, 11, 21)のtorch.Tensorを生成する訓練データ用のデータローダーを作成\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# (32, 1, 11, 21)のtorch.Tensorを生成する検証データ用のデータローダーを作成\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# データローダーが返すミニバッチの先頭データの形状を出力して確認する\n",
        "for (x, t) in train_dataloader: # 訓練データ\n",
        "    print(x.shape)\n",
        "    print(t.shape)\n",
        "    break\n",
        "    \n",
        "for (x, t) in test_dataloader: # テストデータ\n",
        "    print(x.shape)\n",
        "    print(t.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewpYQQnRzfQn"
      },
      "source": [
        "##### 入力7-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BpU5Evl2oLu"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "6. 畳み込みニューラルネットワークの構築\n",
        "'''\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        '''インスタンス変数の初期化\n",
        "        '''\n",
        "        super().__init__() # スーパークラスの__init__()を実行\n",
        "\n",
        "        # 第1層: 畳み込み層1\n",
        "        # (バッチサイズ,1,11,21) -> (バッチサイズ,128,12,22)\n",
        "        self.conv1a = nn.Conv2d(in_channels=1, # 入力チャネル数\n",
        "                                out_channels=128, # 出力チャネル数\n",
        "                                kernel_size=(2, 2), # フィルターサイズ\n",
        "                                stride=(1, 1), # スライド幅\n",
        "                                padding=1, # 周囲に1のパディングを行う\n",
        "                                padding_mode='zeros') # パディング部分を0で埋める\n",
        "        self.dropout1a = nn.Dropout(0.40) # Dropuotの設定\n",
        "        # 畳み込み層へのDropoutの適用は一般的ではないが，既存モデルを踏襲するために設定する\n",
        "        # 第2層: 畳み込み層2\n",
        "        # (バッチサイズ,128,12,22) -> (バッチサイズ,128,7,12)\n",
        "        self.conv1b = nn.Conv2d(in_channels=128, # 入力チャネル数\n",
        "                                out_channels=128, # 出力チャネル数\n",
        "                                kernel_size=(2, 2), # フィルターサイズ\n",
        "                                stride=(2, 2), # スライド幅\n",
        "                                padding=1, # 周囲に1のパディングを行う\n",
        "                                padding_mode='zeros') # パディング部分を0で埋める\n",
        "        self.dropout1b = nn.Dropout(0.40)\n",
        "\n",
        "        # 第3層: 畳み込み層3\n",
        "        # (バッチサイズ,128,7,12) -> (バッチサイズ,256,4,7)\n",
        "        self.conv1c = nn.Conv2d(in_channels=128, # 入力チャネル数\n",
        "                                out_channels=256, # 出力チャネル数\n",
        "                                kernel_size=(2, 2), # フィルターサイズ\n",
        "                                stride=(2, 2), # スライド幅\n",
        "                                padding=1, # 周囲に1のパディングを行う\n",
        "                                padding_mode='zeros') # パディング部分を0で埋める\n",
        "        self.dropout1c = nn.Dropout(0.40)\n",
        "\n",
        "        # 第4層: 畳み込み層4\n",
        "        # (バッチサイズ,256,4,7) -> (バッチサイズ,256,5,8)\n",
        "        self.conv1d = nn.Conv2d(in_channels=256, # 入力チャネル数\n",
        "                                out_channels=256, # 出力チャネル数\n",
        "                                kernel_size=(2, 2), # フィルターサイズ\n",
        "                                stride=(1, 1), # スライド幅\n",
        "                                padding=1, # 周囲に1のパディングを行う\n",
        "                                padding_mode='zeros') # パディング部分を0で埋める\n",
        "        self.dropout1d = nn.Dropout(0.40)\n",
        "\n",
        "        # 第5層: 畳み込み層5\n",
        "        # (バッチサイズ,256,5,8) -> (バッチサイズ,256,6,9)\n",
        "        self.conv1e = nn.Conv2d(in_channels=256, # 入力チャネル数\n",
        "                                out_channels=256, # 出力チャネル数\n",
        "                                kernel_size=(2, 2), # フィルターサイズ\n",
        "                                stride=(1, 1), # スライド幅\n",
        "                                padding=1, # 周囲に1のパディングを行う\n",
        "                                padding_mode='zeros') # パディング部分を0で埋める\n",
        "        self.dropout1e = nn.Dropout(0.40)\n",
        "\n",
        "        # 第6層: 畳み込み層6\n",
        "        # (バッチサイズ,256,6,9) -> (バッチサイズ,512,6,4)\n",
        "        self.conv1f = nn.Conv2d(in_channels=256, # 入力チャネル数\n",
        "                                out_channels=512, # 出力チャネル数\n",
        "                                kernel_size=(1, 2), # フィルターサイズ\n",
        "                                stride=(1, 2), # スライド幅\n",
        "                                padding=0, # 周囲に1のパディングを行う\n",
        "                                padding_mode='zeros') # パディング部分を0で埋める\n",
        "        self.dropout1f = nn.Dropout(0.40)\n",
        "\n",
        "        # 第7層: 畳み込み層7\n",
        "        # (バッチサイズ,512,6,4) -> (バッチサイズ,512,6,4)\n",
        "        self.conv1g = nn.Conv2d(in_channels=512, # 入力チャネル数\n",
        "                                out_channels=512, # 出力チャネル数\n",
        "                                kernel_size=(1, 1), # フィルターサイズ\n",
        "                                stride=(1, 1), # スライド幅\n",
        "                                padding=0, # 周囲に1のパディングを行う\n",
        "                                padding_mode='zeros') # パディング部分を0で埋める\n",
        "        self.dropout1g = nn.Dropout(0.40)\n",
        "\n",
        "        # 第8層: 畳み込み層8\n",
        "        # # (バッチサイズ,512,6,4) -> (バッチサイズ,256,6,4)\n",
        "        self.conv1h = nn.Conv2d(in_channels=512, # 入力チャネル数\n",
        "                                out_channels=256, # 出力チャネル数\n",
        "                                kernel_size=(1, 1), # フィルターサイズ\n",
        "                                stride=(1, 1), # スライド幅\n",
        "                                padding=0, # 周囲に1のパディングを行う\n",
        "                                padding_mode='zeros') # パディング部分を0で埋める\n",
        "        self.dropout1 = nn.Dropout(0.50)\n",
        "\n",
        "        # 第9層: 全結合層1\n",
        "        # (バッチサイズ,256*6*4) -> (バッチサイズ,128)\n",
        "        self.fc1 = nn.Linear(256*6*4, 128)\n",
        "        # ドロップアウト:\n",
        "        self.dropout2 = nn.Dropout(0.25)\n",
        "\n",
        "        # 第10層: 出力層\n",
        "        # (バッチサイズ,128) -> (バッチサイズ,2)\n",
        "        self.fc2 = nn.Linear(128, 2)\n",
        "\n",
        "    # 深層学習モデルを構築する\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1a(x)) # conv1\n",
        "        x = self.dropout1a(x)\n",
        "        x = torch.relu(self.conv1b(x)) # conv2\n",
        "        x = self.dropout1b(x)\n",
        "        x = torch.relu(self.conv1c(x)) # conv3\n",
        "        x = self.dropout1c(x)\n",
        "        x = torch.relu(self.conv1d(x)) # conv4\n",
        "        x = self.dropout1d(x)\n",
        "        x = torch.relu(self.conv1e(x)) # conv5\n",
        "        x = self.dropout1e(x)\n",
        "        x = torch.relu(self.conv1f(x)) # conv6\n",
        "        x = self.dropout1f(x)\n",
        "        x = torch.relu(self.conv1g(x)) # conv7\n",
        "        x = self.dropout1g(x)\n",
        "        x = torch.relu(self.conv1h(x)) # conv8\n",
        "\n",
        "        x = self.dropout1(x)\n",
        "        x = x.view(-1, 256*6*4) # フラット化\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyZARP8qzfTI"
      },
      "source": [
        "##### 入力7-11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dr-Q-psG9i1q"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "7. モデルのインスタンスを生成\n",
        "'''\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 使用可能なデバイス (CPUまたはGPU)を取得する\n",
        "print(device)\n",
        "model = CNN().to(device) # モデルオブジェクトを生成し，使用可能なデバイスを設定する\n",
        "model # モデルの構造を出力する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEKh6nY09wZV"
      },
      "source": [
        "##### 入力7-12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cn68DBn9zfVm"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "8. 損失関数とオプティマイザの生成\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss() # クロスエントロピー誤差のオブジェクトを生成\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # オプティマイザを指定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3q1PQ4-zfX3"
      },
      "source": [
        "##### 入力7-13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A0ihml59z_y"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "9. パラメータの更新処理\n",
        "'''\n",
        "def train_step(x, target):\n",
        "    '''パラメータ更新を行う\n",
        "    '''\n",
        "    model.train() # モデルを訓練(学習)モードにする\n",
        "    preds = model(x) # モデルの出力を取得\n",
        "    pr = precision_recall(preds, target, average='macro', num_classes=2) # precisionとrecallを出力(macroを指定)\n",
        "    loss = criterion(preds, target) # 出力と正解ラベルの誤差から損失を取得\n",
        "    optimizer.zero_grad() # 勾配を0で初期化(累積してしまうため)\n",
        "    loss.backward() # 逆伝播を行うことで勾配を計算する\n",
        "    optimizer.step() # 設定した最適化方法を適用してパラメータを更新する\n",
        "\n",
        "    return loss, preds, pr[0], pr[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmMsBZ-Izfa2"
      },
      "source": [
        "##### 入力7-14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5vhNmcg-AN8"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "10. 評価用データセットを用いてモデルの評価を行う関数\n",
        "'''\n",
        "def test_step(x, target):\n",
        "    '''評価用データセットを入力して損失と予測値を返す\n",
        "    '''\n",
        "    model.eval() # モデルを評価モードにする\n",
        "    preds = model(x) # モデルの出力を取得\n",
        "    pr = precision_recall(preds, target, average='macro', num_classes=2) # precisionとrecallを出力(macroを指定)\n",
        "    loss = criterion(preds, t) # 出力と正解ラベルの誤差から損失を取得\n",
        "\n",
        "    return loss, preds, pr[0], pr[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou3o1nItzfdN"
      },
      "source": [
        "##### 入力7-15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SACR-wG-Mkr"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "11. モデルを使用して学習する\n",
        "'''\n",
        "epochs = 120 # エポック数\n",
        "# 損失と正確度，適合率，再現率の履歴を保存するためのdictオブジェクトを用意しておく\n",
        "history = {'loss':[],'accuracy':[], 'precision':[], 'recall':[], 'test_loss':[], 'test_accuracy':[], 'test_precision':[], 'test_recall':[]}\n",
        "\n",
        "# 収束が停滞したら学習率を減衰するスケジューラー\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer=optimizer, # オプティマイザーを指定\n",
        "    mode='max', # 最大値を監視する\n",
        "    factor=0.1, # 学習率を減衰する割合\n",
        "    patience=5, # 監視対象のエポック数\n",
        "    min_lr=0.0001, # 最小学習率\n",
        "    verbose=True # 学習率を減衰した場合に通知する\n",
        ")\n",
        "\n",
        "# 学習を行う\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc, train_prec, train_recall = 0., 0., 0., 0. # 訓練1エポックあたりの損失，正確度，適合率，再現率を保持する変数\n",
        "    test_loss, test_acc, test_prec, test_recall = 0., 0., 0., 0. # 評価1エポックごとの損失，正確度，適合率，再現率を保持する変数\n",
        "\n",
        "    # 訓練用データセット用のデータローダーを用いて学習する\n",
        "    for (x, t) in train_dataloader:\n",
        "        x, t = x.to(device), t.to(device) # torch.Tensorオブジェクトへのデバイスの割り当て\n",
        "        loss, preds, prec, recall = train_step(x, t) # 上で定義した関数で学習を行い，返り値を得る\n",
        "        train_loss += loss.item() # 結果の格納\n",
        "        train_prec += prec.item()\n",
        "        train_recall += recall.item()\n",
        "        train_acc += accuracy_score(t.tolist(), preds.argmax(dim=-1).tolist())\n",
        "\n",
        "    # 評価データセット用のデータローダーを用いて評価する\n",
        "    for (x, t) in test_dataloader:\n",
        "        x, t = x.to(device), t.to(device) # torch.Tensorオブジェクトにデバイスを割り当てる\n",
        "        loss, preds, prec, recall = test_step(x, t) # 上で定義した関数で評価データセットに関しての返り値を得る\n",
        "        test_loss += loss.item() # 結果の格納\n",
        "        test_prec += prec.item()\n",
        "        test_recall += recall.item()\n",
        "        test_acc += accuracy_score(t.tolist(), preds.argmax(dim=-1).tolist())\n",
        "        \n",
        "    # 訓練時の損失，正確度，適合率，再現率の平均値を取得\n",
        "    avg_train_loss, avg_train_acc, = train_loss / len(train_dataloader), train_acc / len(train_dataloader)\n",
        "    avg_train_prec, avg_train_recall = train_prec / len(train_dataloader), train_recall / len(train_dataloader)\n",
        "\n",
        "    # 評価時の損失，正確度，適合率，再現率の平均値を取得\n",
        "    avg_test_loss, avg_test_acc, = test_loss / len(test_dataloader), test_acc / len(test_dataloader)\n",
        "    avg_test_prec, avg_test_recall = test_prec / len(test_dataloader), test_recall / len(test_dataloader)\n",
        "\n",
        "    # 用意しておいたリストに学習用データセットの性能評価結果を保存する\n",
        "    history['loss'].append(avg_train_loss)\n",
        "    history['accuracy'].append(avg_train_acc)\n",
        "    history['precision'].append(avg_train_prec)\n",
        "    history['recall'].append(avg_train_recall)\n",
        "\n",
        "    # 用意しておいたリストに評価用データセットの性能評価結果を保存する\n",
        "    history['test_loss'].append(avg_test_loss)\n",
        "    history['test_accuracy'].append(avg_test_acc)\n",
        "    history['test_precision'].append(avg_test_prec)\n",
        "    history['test_recall'].append(avg_test_recall)\n",
        "    \n",
        "    # 1エポックごとに結果を出力(小数点以下4桁を指定している)\n",
        "    print('epoch({0}) train_loss: {1:.4} train_acc: {2:.4} train_precision: {3:.4} train_recall: {4:.4}'.format(\n",
        "            epoch+1, avg_train_loss, avg_train_acc, avg_train_prec, avg_train_recall)\n",
        "    )\n",
        "    print('epoch({0}) test_loss: {1:.4} test_acc: {2:.4} test_precision: {3:.4} test_recall: {4:.4}'.format(\n",
        "            epoch+1, avg_test_loss, avg_test_acc, avg_test_prec, avg_test_recall)\n",
        "    )\n",
        "    scheduler.step(avg_test_acc) # スケジューラーを用いて性能を監視する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZyZn7j8zffr"
      },
      "source": [
        "##### 入力7-16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbMWHl74BHZo"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "12. 損失と精度をグラフにする\n",
        "'''\n",
        "# 損失に関するグラフを描画\n",
        "plt.plot(history['loss'], marker='.', label='loss (Training)')\n",
        "plt.plot(history['test_loss'], marker='.', label='loss (Test)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "\n",
        "# 正解率に関するグラフを描画\n",
        "plt.plot(history['accuracy'], marker='.', label='accuracy (Training)')\n",
        "plt.plot(history['test_accuracy'], marker='.', label='accuracy (Test)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}