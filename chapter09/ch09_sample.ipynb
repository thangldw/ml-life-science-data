{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vW0KVthWwan"
      },
      "source": [
        "# 第9章　実践編4：エピジェネティクスを含む多階層の統合によるがん研究\n",
        "\n",
        "- 浅田　健\n",
        "- 浜本隆二"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-8cpfauXbkt"
      },
      "source": [
        "##### 入力9-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UE8qvarifdj"
      },
      "outputs": [],
      "source": [
        "# ライブラリのインポート\n",
        "import argparse\n",
        "from cmath import e\n",
        "import copy\n",
        "import glob\n",
        "import math\n",
        "import pwd\n",
        "from tkinter import E\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        " \n",
        "import pandas as pd\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPiEHWEwXfQ5"
      },
      "source": [
        "##### 入力9-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BT1jhPIDiif8"
      },
      "outputs": [],
      "source": [
        "class AEDataset():\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.Tensor(X.values)\n",
        "        self.y = torch.Tensor(y.values)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyMZsd7DXfTe"
      },
      "source": [
        "##### 入力9-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lXLqj6XisB-"
      },
      "outputs": [],
      "source": [
        "# エンコーダの定義\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, encoding_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, encoding_dim[0])\n",
        "        self.pool1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(encoding_dim[0], encoding_dim[1])\n",
        "        self.pool2 = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        x = self.pool2(x)\n",
        "        return x\n",
        "\n",
        "# デコーダの定義\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, encoding_dim, input_size):\n",
        "        super().__init__()\n",
        "        self.fc3 = nn.Linear(encoding_dim[1], encoding_dim[0])\n",
        "        self.fc4 = nn.Linear(encoding_dim[0], input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.tanh(self.fc3(x))\n",
        "        x = torch.tanh(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, input_size=13767, encoding_dim=[500, 100]):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(input_size, encoding_dim)\n",
        "        self.decoder = Decoder(encoding_dim, input_size)\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bm61252XfV_"
      },
      "source": [
        "##### 入力9-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeZr8tnei4qM"
      },
      "outputs": [],
      "source": [
        "# トレーニング関数\n",
        "def train_model(model, loss, optimizer, data_loader, epochs, fout, device):\n",
        "\n",
        "    # 初期化\n",
        "    pkl_queue = deque()\n",
        "    best_loss = 100.0\n",
        "    best_epoch = 0\n",
        "    best_model_weights = model.state_dict()\n",
        "    since = time.time()\n",
        "    end = time.time()\n",
        "\n",
        "    print(model, \"\\n\")\n",
        "\n",
        "    # エポックに対するループ処理\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch:{}/{}\".format(epoch+1, epochs), end=\"\")\n",
        "        print(\"Epoch:{}/{}\".format(epoch+1, epochs), end=\"\", file=fout)\n",
        "\n",
        "        # データセットに対するループ処理(ここではtrainデータセットに対してのみ)\n",
        "        for phase in [\"train\"]:\n",
        "            model.train(True)\n",
        "\n",
        "            # データの指定\n",
        "            data = data_loader[phase]\n",
        "\n",
        "            # 初期化\n",
        "            running_loss = 0\n",
        "\n",
        "            # ミニバッチに対するループ処理\n",
        "        for idx, (data_train, target_train) in enumerate(data):\n",
        "            optimizer.zero_grad()\n",
        "            x, y = data_train.to(device), target_train.to(device)\n",
        "\n",
        "            with torch.set_grad_enabled(phase == \"train\"):\n",
        "                y_pred = model(x)\n",
        "                l = loss(y_pred, y)\n",
        "                l.backward()\n",
        "                optimizer.step()\n",
        "            # 損失のアップデート\n",
        "            running_loss += l.item()\n",
        "\n",
        "        # MSEをトラッキング\n",
        "        epoch_loss = running_loss / (len(data)/len(x))\n",
        "    \n",
        "        # 最も損失が低かったモデルを保存\n",
        "        if epoch_loss < best_loss:\n",
        "            best_loss = epoch_loss\n",
        "            best_epoch = epoch\n",
        "            best_model_weights = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), \"{}_epoch{}.pkl\".format(fout.name.split(\". txt\")[0], epoch+1))\n",
        "            pkl_queue.append(\"{}_epoch{}.pkl\".format(fout.name.split(\".txt\")[0], epoch+1))\n",
        "            if len(pkl_queue) > 1:\n",
        "                pkl_file = pkl_queue.popleft()\n",
        "                os.remove(pkl_file)\n",
        "        \n",
        "        # 予測の打ち出し\n",
        "        print(\"\\t{} Loss: {:.4f} Time: {:.4f}\".format(phase, epoch_loss, time. time()-end), end=\"\")\n",
        "        print(\"\\t{} Loss: {:.4f} Time: {:.4f}\".format(phase, epoch_loss, time. time()-end), end=\"\", file=fout)\n",
        "        print(\"\\n\", end=\"\")\n",
        "        print(\"\\n\", end=\"\", file=fout)\n",
        "\n",
        "        end = time.time()\n",
        "\n",
        "    # トレーニング結果を表示\n",
        "    time_elapsed = time.time() - since\n",
        "    print(\"\\nTraining completed in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print(\"Best loss: {:.4f} at epoch {}\".format(best_loss, best_epoch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TRQ4xbHXfYZ"
      },
      "source": [
        "##### 入力9-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeVCFSeqjx-I"
      },
      "outputs": [],
      "source": [
        "def plot_loss(file, name):\n",
        "\n",
        "    # トレーニングログファイルの読み込み\n",
        "    df = pd.read_csv(file, header=None, sep=r\"\\s+\")\n",
        "\n",
        "    # 線グラフを作成\n",
        "    fig, ax = plt.subplots()\n",
        "    plt.plot(range(len(df)), df.iloc[:, 3])\n",
        "    ax.set_title(f\"MSE loss for \\n{file}\")\n",
        "    ax.set_xlabel(\"Epochs\")\n",
        "    ax.set_ylabel(\"MSE loss\")\n",
        "    fig.savefig(f\"{name}.png\")\n",
        "    plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYJkRB62Xfaf"
      },
      "source": [
        "##### 入力9-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHuKz1a_j6fR"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, device):\n",
        "\n",
        "    # 初期化 \n",
        "    running_mse = 0\n",
        "    preds = []\n",
        "\n",
        "    # データとモデルをセット\n",
        "    data = data_loader[\"test\"]\n",
        "    model.eval()\n",
        "\n",
        "    # ミニバッチに対するループ処理\n",
        "    for data_test, target_test in data:\n",
        "        x, y = data_test.to(device), target_test.to(device)\n",
        "\n",
        "    # 予測\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(x)\n",
        "\n",
        "        # MSEの計算\n",
        "        squared_error = ((y_pred - x)*(y_pred - x)).sum().data\n",
        "        running_mse += squared_error\n",
        "\n",
        "        preds.append(y_pred[0])\n",
        "    \n",
        "    # 予測スコアを表示\n",
        "    preds = np.vstack(preds)\n",
        "    mse = math.sqrt(running_mse / len(data))\n",
        "    print(f\"MSE: {mse}\")\n",
        "    \n",
        "    return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0yMICSuXfdH"
      },
      "source": [
        "##### 入力9-7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UShOfHalkNBz"
      },
      "outputs": [],
      "source": [
        "## このセルは抜粋したものであるため，単独で実行してもエラーが出るので注意されたい\n",
        "\n",
        "# オートエンコーダモデルのロード\n",
        "model = AutoEncoder(13767, [500, 100])\n",
        "model = model.to(device)\n",
        "\n",
        "# トレーニングデータセットの作成\n",
        "AEdata = AEDataset(X, X)\n",
        "train_data = DataLoader(AEdata, batch_size=args.batch, shuffle=True)\n",
        "test_data = DataLoader(AEdata, batch_size=args.batch, shuffle=False)\n",
        "data_loader = {\"train\": train_data, \"test\": test_data}\n",
        "\n",
        "# モデルをトレーニングするための設定\n",
        "loss = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.decay, momentum=args. momentum, nesterov=True)\n",
        "\n",
        "# トレーニングログファイルの設定\n",
        "train_log = f\"AE_lr{args.lr}_decay{args.decay}_momentum{args.momentum}_epochs{args.epochs}_batch{args.batch}.txt\"\n",
        "fout = open(check_path(str(Path(path, args.output, \"AutoEncoder\", train_log))), \"w\")\n",
        "\n",
        "# オートエンコーダのトレーニング\n",
        "train_model(model, loss, optimizer, data_loader, args.epochs, fout, device)\n",
        "\n",
        "fout.close()\n",
        "\n",
        "# トレーニング損失の書き出し\n",
        "plot_loss(str(Path(path, args.output, \"AutoEncoder\", train_log)), check_path(str(Path(path, args.output, \"AutoEncoder\", f\"LUAD_epoch{args.epochs}_loss\"))))\n",
        "\n",
        "# 最も性能の良いオートエンコーダモデルの読み込み\n",
        "trained_model = glob.glob(str(Path(path, args.output, \"AutoEncoder\", \"{}_*.pkl\".format(train_log.split(\".txt\")[0]))))[0]\n",
        "model.load_state_dict(torch.load(trained_model), strict=False)\n",
        "\n",
        "# 学習済みモデルを用いた予測\n",
        "decoded_result = eval_model(model, data_loader, device)\n",
        "print(decoded_result)\n",
        "\n",
        "# 最も良い学習済みモデルからの特徴抽出\n",
        "encoded_bottleneck = model.encoder(torch.Tensor(X.values)).detach().numpy()\n",
        "print(encoded_bottleneck)\n",
        "\n",
        "# 予測結果の保存\n",
        "np.savetxt(check_path(str(Path(path, args.output, \"Encoder\", f\"LUAD_epoch{args.epochs}_std_mmRNA.csv\"))), encoded_bottleneck, delimiter=\",\")\n",
        "np.save(check_path(str(Path(path, args.output, \"Encoder\", f\"LUAD_epoch{args.epochs}_std_mmRNA.npy\"))), encoded_bottleneck)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YzEWAgHXffn"
      },
      "source": [
        "##### 入力9-8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgolooWQkjQF"
      },
      "outputs": [],
      "source": [
        "%%writefile Autoencoder.py\n",
        "\n",
        "# ライブラリのインポート\n",
        "import argparse\n",
        "from cmath import e\n",
        "import copy\n",
        "import glob\n",
        "import math\n",
        "import pwd\n",
        "from tkinter import E\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from collections import deque\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def check_path(filename):\n",
        "\n",
        "    if not Path(filename).is_dir():\n",
        "        Path(filename).parents[0].mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    return filename\n",
        "\n",
        "\n",
        "class AEDataset():\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.Tensor(X.values)\n",
        "        self.y = torch.Tensor(y.values)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# エンコーダの定義\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, encoding_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, encoding_dim[0])\n",
        "        self.pool1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(encoding_dim[0], encoding_dim[1])\n",
        "        self.pool2 = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        x = self.pool2(x)\n",
        "        return x\n",
        "\n",
        "# デコーダの定義\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, encoding_dim, input_size):\n",
        "        super().__init__()\n",
        "        self.fc3 = nn.Linear(encoding_dim[1], encoding_dim[0])\n",
        "        self.fc4 = nn.Linear(encoding_dim[0], input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.tanh(self.fc3(x))\n",
        "        x = torch.tanh(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, input_size=13767, encoding_dim=[500, 100]):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(input_size, encoding_dim)\n",
        "        self.decoder = Decoder(encoding_dim, input_size)\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# トレーニング関数\n",
        "def train_model(model, loss, optimizer, data_loader, epochs, fout, device):\n",
        "\n",
        "    # 初期化\n",
        "    pkl_queue = deque()\n",
        "    best_loss = 100.0\n",
        "    best_epoch = 0\n",
        "    best_model_weights = model.state_dict()\n",
        "    since = time.time()\n",
        "    end = time.time()\n",
        "\n",
        "    print(model, \"\\n\")\n",
        "\n",
        "    # エポックに対するループ処理\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch:{}/{}\".format(epoch+1, epochs), end=\"\")\n",
        "        print(\"Epoch:{}/{}\".format(epoch+1, epochs), end=\"\", file=fout)\n",
        "\n",
        "        # データセットに対するループ処理 (ここではtrainデータセットに対してのみ)\n",
        "        for phase in [\"train\"]:\n",
        "            model.train(True)\n",
        "\n",
        "            # データの指定\n",
        "            data = data_loader[phase]\n",
        "\n",
        "            # 初期化\n",
        "            running_loss = 0\n",
        "\n",
        "            # ミニバッチに対するループ処理\n",
        "            for idx, (data_train, target_train) in enumerate(data):\n",
        "                optimizer.zero_grad()\n",
        "                x, y = data_train.to(device), target_train.to(device)\n",
        "\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    y_pred = model(x)\n",
        "                    l = loss(y_pred, y)\n",
        "\n",
        "                    l.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                # 損失のアップデート\n",
        "                running_loss += l.item()\n",
        "\n",
        "            # MSEをトラッキング\n",
        "            epoch_loss = running_loss / (len(data)/len(x))\n",
        "\n",
        "            # 最も損失が低かったモデルを保存\n",
        "            if epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_epoch = epoch\n",
        "                best_model_weights = copy.deepcopy(model.state_dict())\n",
        "                torch.save(model.state_dict(), \"{}_epoch{}.pkl\".format(fout.name.split(\".txt\")[0], epoch+1))\n",
        "                pkl_queue.append(\"{}_epoch{}.pkl\".format(fout.name.split(\".txt\")[0], epoch+1))\n",
        "                if len(pkl_queue) > 1:\n",
        "                    pkl_file = pkl_queue.popleft()\n",
        "                    os.remove(pkl_file)\n",
        "\n",
        "            #予測の打ち出し\n",
        "            print(\"\\t{} Loss: {:.4f} Time: {:.4f}\".format(phase, epoch_loss, time.time()-end), end=\"\")\n",
        "            print(\"\\t{} Loss: {:.4f} Time: {:.4f}\".format(phase, epoch_loss, time.time()-end), end=\"\", file=fout)\n",
        "            print(\"\\n\", end=\"\")\n",
        "            print(\"\\n\", end=\"\", file=fout)\n",
        "\n",
        "            end = time.time()\n",
        "\n",
        "    # トレーニング結果を表示\n",
        "    time_elapsed = time.time() - since\n",
        "    print(\"\\nTraining completed in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print(\"Best loss: {:.4f} at epoch {}\".format(best_loss, best_epoch))\n",
        "\n",
        "\n",
        "def plot_loss(file, name):\n",
        "\n",
        "    # トレーニングログファイルの読み込み\n",
        "    df = pd.read_csv(file, header=None, sep=r\"\\s+\")\n",
        "\n",
        "    # 線グラフを作成\n",
        "    fig, ax = plt.subplots()\n",
        "    plt.plot(range(len(df)), df.iloc[:, 3])\n",
        "    ax.set_title(f\"MSE loss for \\n{file}\")\n",
        "    ax.set_xlabel(\"Epochs\")\n",
        "    ax.set_ylabel(\"MSE loss\")\n",
        "    fig.savefig(f\"{name}.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "def eval_model(model, data_loader, device):\n",
        "\n",
        "    # 初期化\n",
        "    running_mse = 0\n",
        "    preds = []\n",
        "\n",
        "    # データとモデルをセット\n",
        "    data = data_loader[\"test\"]\n",
        "    model.eval()\n",
        "\n",
        "    # ミニバッチに対するループ処理\n",
        "    for data_test, target_test in data:\n",
        "        x, y = data_test.to(device), target_test.to(device)\n",
        "\n",
        "        # 予測\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(x)\n",
        "\n",
        "            # MSEの計算\n",
        "            squared_error = ((y_pred - x)*(y_pred - x)).sum().data\n",
        "            running_mse += squared_error\n",
        "\n",
        "            preds.append(y_pred[0])\n",
        "\n",
        "    # 予測スコアを表示\n",
        "    preds = np.vstack(preds)\n",
        "    mse = math.sqrt(running_mse / len(data))\n",
        "    print(f\"MSE: {mse}\")\n",
        "\n",
        "    return preds\n",
        "\n",
        "\n",
        "def parseArgs():\n",
        "    \n",
        "    parser = argparse.ArgumentParser(description=\"Train autoencoder model\")\n",
        "\n",
        "    # 必要な引数\n",
        "    parser.add_argument(\"-i\", \"--input\", type=str, required=True, help=\"Input data to train the model on\")\n",
        "\n",
        "    # オプショナルな引数\n",
        "    parser.add_argument(\"-b\", \"--batch\", type=int, default=1, help=\"Training minibatch size (default: 1)\")\n",
        "    parser.add_argument(\"-e\", \"--epochs\", type=int, default=150, help=\"Training epochs (default: 150)\")\n",
        "\n",
        "    parser.add_argument(\"-l\", \"--lr\", type=float, default=0.01, help=\"Optimizer learning rate (default: 0.01)\")\n",
        "    parser.add_argument(\"-d\", \"--decay\", type=float, default=1e-6, help=\"Optimizer decay rate (default: 1e-6)\")\n",
        "    parser.add_argument(\"-m\", \"--momentum\", type=float, default=0.9, help=\"Optimizer momentum (default: 0.9)\")\n",
        "\n",
        "    parser.add_argument(\"-o\", \"--output\", type=str, default=\"AE_LUAD_PyTorch\", help=\"Output directory name (default: AE_LUAD_PyTorch)\")\n",
        "\n",
        "    # 引数のコマンドラインにおける打ち出し\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    print(\"Called with args:\")\n",
        "    print(f\"{args}\\n\")\n",
        "\n",
        "    return args\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    # コマンドライン引数をパースする\n",
        "    args = parseArgs()\n",
        "\n",
        "    # 変数の初期化\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    path = Path.cwd()\n",
        "\n",
        "    # インプットデータをデータフレームとして読み込み\n",
        "    df = pd.read_csv(Path(path, args.input), header=0, usecols=lambda c: c not in [\"GeneSymbol\", \"Platform\"])\n",
        "    df = df.transpose()\n",
        "    X = df.astype(np.float32)\n",
        "\n",
        "     # オートエンコーダモデルのロード\n",
        "    model = AutoEncoder(13767, [500, 100])\n",
        "    model = model.to(device)\n",
        "\n",
        "    # トレーニングデータセットの作成\n",
        "    AEdata = AEDataset(X, X)\n",
        "    train_data = DataLoader(AEdata, batch_size=args.batch, shuffle=True)\n",
        "    test_data = DataLoader(AEdata, batch_size=args.batch, shuffle=False)\n",
        "    data_loader = {\"train\": train_data, \"test\": test_data}\n",
        "    \n",
        "    # モデルをトレーニングするための設定\n",
        "    loss = nn.MSELoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.decay, momentum=args.momentum, nesterov=True)\n",
        "\n",
        "    # トレーニングログファイルの設定。\n",
        "    train_log = f\"AE_lr{args.lr}_decay{args.decay}_momentum{args.momentum}_epochs{args.epochs}_batch{args.batch}.txt\"\n",
        "    fout = open(check_path(str(Path(path, args.output, \"AutoEncoder\", train_log))), \"w\")\n",
        "\n",
        "    # オートエンコーダのトレーニング\n",
        "    train_model(model, loss, optimizer, data_loader, args.epochs, fout, device)\n",
        "\n",
        "    fout.close()\n",
        "\n",
        "    # トレーニング損失の書き出し\n",
        "    plot_loss(str(Path(path, args.output, \"AutoEncoder\", train_log)), check_path(str(Path(path, args.output, \"AutoEncoder\", f\"LUAD_epoch{args.epochs}_loss\"))))\n",
        "\n",
        "    # 最も性能の良いオートエンコーダモデルの読み込み\n",
        "    trained_model = glob.glob(str(Path(path, args.output, \"AutoEncoder\", \"{}_*.pkl\".format(train_log.split(\".txt\")[0]))))[0]\n",
        "    model.load_state_dict(torch.load(trained_model), strict=False)\n",
        "\n",
        "    # 学習済みモデルを用いた予測\n",
        "    decoded_result = eval_model(model, data_loader, device)\n",
        "    print(decoded_result)\n",
        "\n",
        "    # 最も良い学習済モデルからの特徴抽出\n",
        "    encoded_bottleneck = model.encoder(torch.Tensor(X.values)).detach().numpy()\n",
        "    print(encoded_bottleneck)\n",
        "\n",
        "    # 予測結果の保存\n",
        "    np.savetxt(check_path(str(Path(path, args.output, \"Encoder\", f\"LUAD_epoch{args.epochs}_std_mmRNA.csv\"))), encoded_bottleneck, delimiter=\",\")\n",
        "    np.save(check_path(str(Path(path, args.output, \"Encoder\", f\"LUAD_epoch{args.epochs}_std_mmRNA.npy\"))), encoded_bottleneck)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tITx0aKOXfiI"
      },
      "source": [
        "##### 入力9-9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqtQaARMnKcn"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvpBsR2YXfku"
      },
      "source": [
        "##### 入力9-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhgvTNRdnOge"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDWTaQHCXfnP"
      },
      "source": [
        "##### 入力9-11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJRt-HD5nQ0b"
      },
      "outputs": [],
      "source": [
        "!python Autoencoder.py -i input_file_yodosya_zikkenigaku.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeJMgDAVXfpj"
      },
      "source": [
        "##### 入力9-12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36QdGM4LnU5q"
      },
      "outputs": [],
      "source": [
        "!python Autoencoder.py -i input_file_yodosya_zikkenigaku.csv -e 10 -o test/epoch10/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdv6xAD3XfsA"
      },
      "source": [
        "##### 入力9-13\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_Dgcpj2nYGf"
      },
      "outputs": [],
      "source": [
        "conda info -e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fp6eoX5XfvE"
      },
      "source": [
        "##### 入力9-14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQRmHltlnat-"
      },
      "outputs": [],
      "source": [
        "python3 Autoencoder.py -i input_file_yodosya_zikkenigaku.csv"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}